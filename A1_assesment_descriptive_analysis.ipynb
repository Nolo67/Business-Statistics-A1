{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLy38V3/QdryhIZ8PRcahc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FadoxXW8kKgC"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: storing the path to the dataset\n",
        "file = \"/content/A1 combined dataset.csv\"\n",
        "\n",
        "\n",
        "# Step 3: reading the file into Python through pandas\n",
        "data = pd.read_csv(file)\n",
        "\n",
        "\n",
        "# Step 4 (optional): checking results\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "3U656wbBrPXw",
        "outputId": "061d9387-8cea-42c4-84fd-a8ece551898d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/A1 combined dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-020738c8e3e8>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 3: reading the file into Python through pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/A1 combined dataset.csv'"
          ]
        }
      ]
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "data.groupby('Customer_Segment').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)\n",
        "plt.title('Customer_Segment')\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ZbrwKdnHiLpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = data['Customer_Segment'].value_counts()\n",
        "plt.pie(sizes, labels=sizes.index, autopct='%1.1f%%', colors=sns.color_palette('Dark2'), wedgeprops=dict(width=0.3))\n",
        "plt.title('Customer_Segment Donut Chart')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tjCZEvcRoLfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = data['Traffic_Source'].value_counts()\n",
        "plt.pie(sizes, labels=sizes.index, autopct='%1.1f%%', colors=sns.color_palette('Dark2'), wedgeprops=dict(width=0.3))\n",
        "plt.title('Traffic Source Donut Chart')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L97Nfno0nYM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "data.groupby('Traffic_Source').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)\n",
        "plt.title('Traffic Source')\n",
        "\n",
        "\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oFoa17YPiBsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#import seaborn as sns\n",
        "#_df_26.groupby('Product_Category').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "#plt.gca().spines[['top', 'right',]].set_visible(False)\n",
        "#plt.title('Product_Category')\n",
        "\n",
        "\n",
        "sizes = data['Product_Category'].value_counts()\n",
        "plt.pie(sizes, labels=sizes.index, autopct='%1.1f%%', colors=sns.color_palette('Dark2'), wedgeprops=dict(width=0.3))\n",
        "plt.title('Product_Category Donut Chart')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "22dvyTZ2h-s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "GKn5ZV4GYoEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Violin plot of Revenue by Conversion\n",
        "sns.violinplot(x='Conversion', y='Revenue', data=data, palette=\"pastel\")\n",
        "plt.title(\"Revenue Distribution by Conversion\")\n",
        "plt.show()\n",
        "\n",
        "# Violin plot of Session Duration by Discount Applied\n",
        "sns.violinplot(x='Discount_Applied', y='Revenue', data=data, palette=\"muted\")\n",
        "plt.title(\"Revenue Distribution by Discount Applied\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Violin plot of Session Duration by Discount Applied\n",
        "sns.violinplot(x='Customer_Segment', y='Revenue', data=data, palette=\"muted\")\n",
        "plt.title(\"Revenue Distribution by Customer_Segment\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VkPVuxW6rhJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = data['Customer_Segment'].unique()\n",
        "unique_values"
      ],
      "metadata": {
        "id": "HW42fYNJ8Xcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x='Customer_Segment', y='Revenue', hue='Discount_Applied', data=data, palette=\"muted\")\n",
        "plt.title(\"Revenue Distribution by Customer Segment and Discount Applied\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JV4RiHASKmtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Customer_Segment', y='Revenue', hue='Discount_Applied', data=data, estimator='median', palette=\"muted\")\n",
        "plt.title(\"Median Revenue by Customer Segment and Discount Applied\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "q3RNNvQlMkks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.FacetGrid(data, col=\"Customer_Segment\", hue=\"Discount_Applied\", palette=\"muted\", height=4, aspect=1)\n",
        "g.map(sns.histplot, \"Revenue\", kde=True, alpha=0.6).add_legend()\n",
        "plt.suptitle(\"Revenue Distribution by Customer Segment and Discount Applied\")\n",
        "plt.subplots_adjust(top=0.85)  # Adjust title position\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "52jdY_GANEe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.FacetGrid(data, col=\"Customer_Segment\", hue=\"Discount_Applied\", palette=\"muted\", height=4, aspect=0.7)\n",
        "g.map(sns.violinplot, \"Discount_Applied\", \"Revenue\", order=[0, 1], split=True)\n",
        "g.add_legend()\n",
        "plt.suptitle(\"Revenue Distribution by Customer Segment and Discount Applied\")\n",
        "plt.subplots_adjust(top=0.85)  # Adjust title position\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ig2xUA4SP_p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming you have a DataFrame 'df' with 'Conversion' and 'Revenue' columns\n",
        "summary_stats = data.groupby('Conversion')['Revenue'].agg([\n",
        "    'mean', 'median', 'std', 'min', 'max', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)\n",
        "]).rename(columns={'<lambda_0>': '25th_percentile', '<lambda_1>': '75th_percentile'})\n",
        "\n",
        "print(summary_stats)\n"
      ],
      "metadata": {
        "id": "Uj7veNQSyC2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming you have a DataFrame 'df' with 'Conversion' and 'Revenue' columns\n",
        "summary_stats = data.groupby('Conversion')['Revenue'].agg([\n",
        "    'mean', 'median', 'std', 'min', 'max', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)\n",
        "]).rename(columns={'<lambda_0>': '25th_percentile', '<lambda_1>': '75th_percentile'})\n",
        "\n",
        "print(summary_stats)\n"
      ],
      "metadata": {
        "id": "MoQKj879sa8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the session duration to its absolute value to disregard any negative signs\n",
        "data['Session_Duration'] = data['Session_Duration'].abs()\n",
        "\n",
        "# Verify that the conversion worked by displaying summary statistics for Session_Duration\n",
        "session_duration_summary = data['Session_Duration'].describe()\n",
        "print(session_duration_summary)"
      ],
      "metadata": {
        "id": "nHTDdAvygCIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = data[['Clicks', 'Revenue','Visitors','Bounce_Rate','Page_Views','Clicks','Conversion_Rate']].describe()\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "WzB23PemaoND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Descriptive Statistics\n",
        "print(\"Descriptive Statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Set up the layout for visualizations\n",
        "fig, axes = plt.subplots(3, 2, figsize=(16, 18))\n",
        "fig.suptitle(\"Data Visualization: Distributions and Correlations\", fontsize=16)\n",
        "\n",
        "# Histogram of Revenue\n",
        "sns.histplot(data['Revenue'], kde=True, ax=axes[0, 0], color='skyblue')\n",
        "axes[0, 0].set_title(\"Revenue Distribution\")\n",
        "\n",
        "# Histogram of Session Duration\n",
        "sns.histplot(data['Session_Duration'], kde=True, ax=axes[0, 1], color='salmon')\n",
        "axes[0, 1].set_title(\"Session Duration Distribution\")\n",
        "\n",
        "# Boxplot of Bounce Rate\n",
        "sns.boxplot(x=data['Bounce_Rate'], ax=axes[1, 0], color='lightgreen')\n",
        "axes[1, 0].set_title(\"Bounce Rate Spread\")\n",
        "\n",
        "# Boxplot of Conversion Rate\n",
        "sns.boxplot(x=data['Conversion_Rate'], ax=axes[1, 1], color='lightcoral')\n",
        "axes[1, 1].set_title(\"Conversion Rate Spread\")\n",
        "\n",
        "# Select only numeric columns for correlation calculation\n",
        "numeric_data = data.select_dtypes(include=['number'])\n",
        "# Calculate and plot Correlation heatmap\n",
        "correlation_matrix = numeric_data.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", ax=axes[2, 0], cbar_kws={'shrink': .8})\n",
        "axes[2, 0].set_title(\"Correlation Heatmap\")\n",
        "axes[2, 1].axis('off')  # Keep the layout clean\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FFfcqI57rDlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['date'] = pd.to_datetime(data['Day'], format='%m/%d/%y')\n",
        "data.info()"
      ],
      "metadata": {
        "id": "xqT6OMXj6dMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting range of dates\n",
        "\n",
        "start_date = data['date'].min()\n",
        "end_date = data['date'].max()\n",
        "\n",
        "start_date, end_date"
      ],
      "metadata": {
        "id": "HTr7BIQP7uz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tbmSM9JMxEQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set Date as index\n",
        "df.set_index('Day', inplace=True)\n",
        "\n",
        "# Plotting the time series for Conversion Rate\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df.index, df['Conversion_Rate'], label='Conversion Rate')\n",
        "plt.title('Conversion Rate Over Time')\n",
        "plt.xlabel('Day')\n",
        "plt.ylabel('Conversion Rate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting the time series for Session Duration\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df.index, df['Revenue'], label='Revenue', color='green')\n",
        "plt.title('Session Duration Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Session Duration (minutes)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Calculating and plotting the rolling averages\n",
        "rolling_window = 3  # 3-day rolling average\n",
        "df['Rolling_Conversion_Rate'] = df['Conversion_Rate'].rolling(window=rolling_window).mean()\n",
        "df['Rolling_Session_Duration'] = df['Session_Duration'].rolling(window=rolling_window).mean()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df.index, df['Conversion_Rate'], label='Conversion Rate')\n",
        "plt.plot(df.index, df['Rolling_Conversion_Rate'], label=f'{rolling_window}-Day Rolling Average', color='orange')\n",
        "plt.title('Conversion Rate Over Time with Rolling Average')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Conversion Rate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df.index, df['Session_Duration'], label='Session Duration', color='green')\n",
        "plt.plot(df.index, df['Rolling_Session_Duration'], label=f'{rolling_window}-Day Rolling Average', color='red')\n",
        "plt.title('Session Duration Over Time with Rolling Average')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Session Duration (minutes)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SA4zY6sg8HCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set Date as index\n",
        "df.set_index('Day', inplace=True)\n",
        "\n",
        "# Calculate the rolling average\n",
        "rolling_window = 4  # 7-day rolling average\n",
        "df['Rolling_Conversion_Rate'] = df['Conversion_Rate'].rolling(window=rolling_window).mean()\n",
        "\n",
        "# Plotting the time series with the moving average\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df.index, df['Conversion_Rate'], label='Conversion Rate')\n",
        "plt.plot(df.index, df['Rolling_Conversion_Rate'], label=f'{rolling_window}-Day Rolling Average', color='orange')\n",
        "plt.title('Conversion Rate Over Time with Rolling Average')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Conversion Rate')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ucTu0IgGzqsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping by Customer_Segment and Product_Category, then calculating total and average revenue\n",
        "revenue_summary = data.groupby(['Customer_Segment', 'Product_Category'])['Revenue'].agg(['sum', 'mean']).reset_index()\n",
        "\n",
        "# Rename columns for clarity\n",
        "revenue_summary.columns = ['Customer_Segment', 'Product_Category', 'Total_Revenue', 'Average_Revenue']\n",
        "\n",
        "# Display the summary\n",
        "print(revenue_summary)"
      ],
      "metadata": {
        "id": "kZDCycmhiDMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected pivot syntax\n",
        "pivot_table = revenue_summary.pivot(index=\"Customer_Segment\", columns=\"Product_Category\", values=\"Total_Revenue\")\n",
        "\n",
        "# Now you can use the heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(pivot_table, annot=True, cmap=\"YlGnBu\", fmt=\".0f\")\n",
        "plt.title('Total Revenue by Customer Segment and Product Category')\n",
        "plt.ylabel('Customer Segment')\n",
        "plt.xlabel('Product Category')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GWVjGO3riSKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select relevant columns\n",
        "correlation_matrix = data[['Session_Duration', 'Page_Views', 'Clicks', 'Bounce_Rate']].corr()\n",
        "\n",
        "# Plot correlation matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix of Website Metrics\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WCWIXmhzu43B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Define the categorical grouping column (e.g., Customer_Segment)\n",
        "group_col = 'Customer_Segment'\n",
        "\n",
        "# Select only numeric columns\n",
        "numeric_columns = data.select_dtypes(include='number').columns\n",
        "\n",
        "# Run ANOVA for each numeric column\n",
        "anova_results = {}\n",
        "for col in numeric_columns:\n",
        "    # Drop NaN values for the ANOVA test\n",
        "    groups = [group[col].dropna() for name, group in data.groupby(group_col)]\n",
        "    # Perform ANOVA\n",
        "    f_val, p_val = stats.f_oneway(*groups)\n",
        "    anova_results[col] = {'F-Value': f_val, 'p-Value': p_val}\n",
        "\n",
        "# Convert results to a DataFrame for easier interpretation\n",
        "anova_df = pd.DataFrame(anova_results).T\n",
        "print(anova_df)\n"
      ],
      "metadata": {
        "id": "RK2P99vv2r_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Define the grouping variable (Conversion) and numeric variables\n",
        "group_col = 'Conversion'\n",
        "numeric_columns = ['Session_Duration', 'Page_Views', 'Clicks']\n",
        "\n",
        "# Run ANOVA for each numeric column\n",
        "anova_results = {}\n",
        "for col in numeric_columns:\n",
        "    # Group the data by Conversion and extract the values for each group\n",
        "    groups = [group[col].dropna() for name, group in data.groupby(group_col)]\n",
        "    # Perform ANOVA\n",
        "    f_val, p_val = stats.f_oneway(*groups)\n",
        "    anova_results[col] = {'F-Value': f_val, 'p-Value': p_val}\n",
        "\n",
        "# Convert results to a DataFrame for easier interpretation\n",
        "anova_df = pd.DataFrame(anova_results).T\n",
        "print(anova_df)\n"
      ],
      "metadata": {
        "id": "OAXUj1Hp5O66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_col = 'Discount_Applied'\n",
        "numeric_columns = ['Session_Duration', 'Page_Views', 'Clicks']\n",
        "\n",
        "# Run ANOVA for each numeric column\n",
        "anova_results = {}\n",
        "for col in numeric_columns:\n",
        "    # Group the data by Discount_Applied and extract values for each group\n",
        "    groups = [group[col].dropna() for name, group in data.groupby(group_col)]\n",
        "    # Perform ANOVA\n",
        "    f_val, p_val = stats.f_oneway(*groups)\n",
        "    anova_results[col] = {'F-Value': f_val, 'p-Value': p_val}\n",
        "\n",
        "# Convert results to a DataFrame for easier interpretation\n",
        "anova_df = pd.DataFrame(anova_results).T\n",
        "print(anova_df)"
      ],
      "metadata": {
        "id": "_O-7M6pq70Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the grouping variable (Customer_Segment) and the numeric variable (Session Duration)\n",
        "group_col = 'Customer_Segment'\n",
        "numeric_col = 'Session_Duration'\n",
        "\n",
        "# Group the data by Customer_Segment and extract the values for each group\n",
        "groups = [group[numeric_col].dropna() for name, group in data.groupby(group_col)]\n",
        "\n",
        "# Perform ANOVA\n",
        "f_val, p_val = stats.f_oneway(*groups)\n",
        "\n",
        "# Display the results\n",
        "print(f\"F-Value: {f_val:.4f}\")\n",
        "print(f\"p-Value: {p_val:.4f}\")\n"
      ],
      "metadata": {
        "id": "ck0ljRxh9_Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Box plot of Session Duration by Customer Segment\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='Customer_Segment', y='Session_Duration', data=data, palette=\"muted\")\n",
        "plt.title(\"Session Duration by Customer Segment\")\n",
        "plt.xlabel(\"Customer Segment\")\n",
        "plt.ylabel(\"Session Duration\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3oqwE3mq-YIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the grouping variable (e.g., Customer_Segment or Discount_Applied)\n",
        "group_col = 'Discount_Applied' #'Customer_Segment'\n",
        "\n",
        "# List of numeric metrics to analyze\n",
        "numeric_columns = ['Session_Duration', 'Page_Views', 'Clicks', 'Bounce_Rate', 'Revenue']\n",
        "\n",
        "# Run ANOVA for each metric and store the results\n",
        "anova_results = {}\n",
        "for col in numeric_columns:\n",
        "    # Group data by the selected categorical variable and extract values for each group\n",
        "    groups = [group[col].dropna() for name, group in data.groupby(group_col)]\n",
        "    # Perform ANOVA\n",
        "    f_val, p_val = stats.f_oneway(*groups)\n",
        "    anova_results[col] = {'F-Value': f_val, 'p-Value': p_val}\n",
        "\n",
        "# Convert results to a DataFrame for easier interpretation\n",
        "anova_df = pd.DataFrame(anova_results).T\n",
        "print(anova_df)"
      ],
      "metadata": {
        "id": "WLshnHbiDKmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_session_duration = data.groupby('Customer_Segment')['Session_Duration'].mean().reset_index()\n",
        "\n",
        "# Rename columns for clarity\n",
        "average_session_duration.columns = ['Customer_Segment', 'Average_Session_Duration']\n",
        "\n",
        "# Display the result\n",
        "print(average_session_duration)"
      ],
      "metadata": {
        "id": "jhCL9aiREaDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the grouping variable (e.g., Customer_Segment or Discount_Applied)\n",
        "group_col = 'Conversion' #'Customer_Segment'\n",
        "\n",
        "# List of numeric metrics to analyze\n",
        "numeric_columns = ['Session_Duration', 'Page_Views', 'Clicks', 'Bounce_Rate', 'Revenue']\n",
        "\n",
        "# Run ANOVA for each metric and store the results\n",
        "anova_results = {}\n",
        "for col in numeric_columns:\n",
        "    # Group data by the selected categorical variable and extract values for each group\n",
        "    groups = [group[col].dropna() for name, group in data.groupby(group_col)]\n",
        "    # Perform ANOVA\n",
        "    f_val, p_val = stats.f_oneway(*groups)\n",
        "    anova_results[col] = {'F-Value': f_val, 'p-Value': p_val}\n",
        "\n",
        "# Convert results to a DataFrame for easier interpretation\n",
        "anova_df = pd.DataFrame(anova_results).T\n",
        "print(anova_df)"
      ],
      "metadata": {
        "id": "7VEv7Xd7NlFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MIes2G848IRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the two-way ANOVA model\n",
        "model = ols('Revenue ~ C(Discount_Applied) * C(Customer_Segment)', data=data).fit()\n",
        "\n",
        "# Run the ANOVA\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)  # typ=2 for balanced data\n",
        "print(anova_table)\n"
      ],
      "metadata": {
        "id": "D6L0HgTd8Jzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'data' is your DataFrame with columns 'Revenue' and 'Discount_Applied'\n",
        "# Split the data into two groups: discount and no discount\n",
        "revenue_discount = data[data['Discount_Applied'] == 1]['Revenue']\n",
        "revenue_no_discount = data[data['Discount_Applied'] == 0]['Revenue']\n",
        "\n",
        "# Run the two-sample t-test\n",
        "t_stat, p_val = stats.ttest_ind(revenue_discount, revenue_no_discount, equal_var=False)  # Use equal_var=False if variances are unequal\n",
        "\n",
        "print(\"T-Statistic:\", t_stat)\n",
        "print(\"p-Value:\", p_val)"
      ],
      "metadata": {
        "id": "8D7_Q0xo-39o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select only the necessary columns\n",
        "data_subset = data[['Customer_Segment', 'Product_Category', 'Discount_Applied', 'Revenue']]\n",
        "\n",
        "# Convert categorical variables to dummy variables, dropping the first category to avoid multicollinearity\n",
        "data_encoded = pd.get_dummies(data_subset, columns=['Customer_Segment', 'Product_Category'], drop_first=True)\n",
        "\n",
        "# Convert boolean columns to integers\n",
        "X = X.astype({col: 'int' for col in X.select_dtypes(include='bool').columns})\n",
        "\n",
        "print(data_encoded)"
      ],
      "metadata": {
        "id": "r7OmpDXpFrhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "id": "wS4mZgbaHsWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data types of X and y\n",
        "print(X.dtypes)\n",
        "\n"
      ],
      "metadata": {
        "id": "A1kMZr31H_Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Select only the necessary columns\n",
        "data_subset = data[['Customer_Segment', 'Product_Category', 'Discount_Applied', 'Revenue']]\n",
        "\n",
        "# Convert categorical variables to dummy variables, dropping the first category to avoid multicollinearity\n",
        "data_encoded = pd.get_dummies(data_subset, columns=['Customer_Segment', 'Product_Category'], drop_first=True)\n",
        "\n",
        "# Define the dependent variable (Revenue)\n",
        "y = data_encoded['Revenue']\n",
        "\n",
        "# Define the independent variables, excluding Revenue\n",
        "X = data_encoded.drop(columns=['Revenue'])\n",
        "\n",
        "# Convert boolean columns to integers if any exist\n",
        "X = X.astype({col: 'int' for col in X.select_dtypes(include='bool').columns})\n",
        "\n",
        "# Add a constant to the model to include an intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the OLS regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Display the regression results\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "2825XmWQJ_L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Conversion'] = data['Conversion'].astype(int)\n",
        "\n",
        "# Define the dependent variable (Revenue)\n",
        "y = data['Revenue']\n",
        "\n",
        "# Define the independent variable (Conversion)\n",
        "X = data[['Conversion']]\n",
        "\n",
        "# Add a constant to the model for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the OLS regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Display the regression results\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "w0KaMiOwRi-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dependent variable (Revenue)\n",
        "y = data['Revenue']\n",
        "\n",
        "# Define the independent variables (Bounce Rate, Conversion Rate, Visitors)\n",
        "X = data[['Bounce_Rate', 'Conversion_Rate', 'Visitors']]\n",
        "\n",
        "# Add a constant to the model for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the OLS regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "s-ri3jFASlSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your data is in a DataFrame called `data`\n",
        "data['Day'] = pd.to_datetime(data['Day'])\n"
      ],
      "metadata": {
        "id": "vnkav6MCUGbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['4-Day_Moving_Avg'] = data['Revenue'].rolling(window=4).mean()\n",
        "\n",
        "print(data[['Revenue', '4-Day_Moving_Avg']].head(10))\n"
      ],
      "metadata": {
        "id": "TVEd1-TuUKuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot the original revenue and the 4-day moving average\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(data.index, data['Revenue'], label='Revenue')\n",
        "plt.plot(data.index, data['4-Day_Moving_Avg'], label='4-Day Moving Average', color='orange')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Revenue')\n",
        "plt.title('Revenue and 4-Day Moving Average')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1aHSxZ-yUwEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TDFmPFVUv46"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}